{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d62589e8-fec9-4b5c-9523-e306f549f545",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# performed precomputing process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ccedab-785a-4148-a58f-3a71765c1d2e",
   "metadata": {},
   "source": [
    "developed a precoputing layer where the preprocessed data is converted embeddings and then found the cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e3e6285-4809-489d-a570-5213872225a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajak\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter full path to preprocessed CSV file:\n",
      ">>  C:\\Users\\rajak\\Downloads\\AI Internship\\newdataset.csv\n",
      "Enter text column name (e.g., note_preprocessed):\n",
      ">>  note_preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings for 600 subjects...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|█████████████████████| 103/103 [00:00<00:00, 221.85it/s, Materializing param=pooler.dense.weight]\n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████| 19/19 [00:35<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding Matrix Shape: (600, 384)\n",
      "\n",
      "Computing cosine similarity matrix...\n",
      "\n",
      "Cosine Similarity Matrix Shape: (600, 600)\n",
      "\n",
      "Process Completed Successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# precomputing before sharing symptoms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "# model loading\n",
    "def load_embedding_model(model_name=\"all-MiniLM-L6-v2\"):\n",
    "    return SentenceTransformer(model_name)\n",
    "# loading of data and generate embeddings\n",
    "def compute_embeddings(csv_path: str,\n",
    "                       text_column: str,\n",
    "                       limit: int = 600):\n",
    "\n",
    "    # Clean accidental quotes in path\n",
    "    csv_path = csv_path.strip().strip('\"').strip(\"'\")\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    if text_column not in df.columns:\n",
    "        raise ValueError(f\"Column '{text_column}' not found in dataset.\")\n",
    "\n",
    "    # Select first 600 subjects\n",
    "    df_subset = df.head(limit)\n",
    "\n",
    "    texts = df_subset[text_column].astype(str).tolist()\n",
    "\n",
    "    print(f\"\\nGenerating embeddings for {len(texts)} subjects...\\n\")\n",
    "\n",
    "    model = load_embedding_model()\n",
    "\n",
    "    embeddings = model.encode(\n",
    "        texts,\n",
    "        convert_to_numpy=True,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    # IMPORTANT: Normalize embeddings for proper cosine similarity\n",
    "    embeddings = normalize(embeddings, norm=\"l2\")\n",
    "\n",
    "    return df_subset, embeddings\n",
    "# computing cosine similarity\n",
    "def compute_similarity_matrix(embeddings: np.ndarray):\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "    return similarity_matrix\n",
    "\n",
    "# main execution\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Get User Inputs \n",
    "    csv_path = input(\"Enter full path to preprocessed CSV file:\\n>> \")\n",
    "    text_column = input(\"Enter text column name (e.g., note_preprocessed):\\n>> \")\n",
    "\n",
    "    # Step 1: Generate Embeddings \n",
    "    patient_df, stored_embeddings = compute_embeddings(\n",
    "        csv_path=csv_path,\n",
    "        text_column=text_column,\n",
    "        limit=600\n",
    "    )\n",
    "\n",
    "    print(\"\\nEmbedding Matrix Shape:\", stored_embeddings.shape)\n",
    "\n",
    "    # ---- Step 2: Compute Cosine Similarity ----\n",
    "    print(\"\\nComputing cosine similarity matrix...\\n\")\n",
    "\n",
    "    similarity_matrix = compute_similarity_matrix(stored_embeddings)\n",
    "\n",
    "    print(\"Cosine Similarity Matrix Shape:\", similarity_matrix.shape)\n",
    "\n",
    "    print(\"\\nProcess Completed Successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0f46a0-0695-4359-8dad-a99e4a2b13fb",
   "metadata": {},
   "source": [
    "performed the precomputing process. where the prerocessed file have beeen computed embeddings and then find the cosine similarity using the single reusable code for the existing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baf8b39-984a-4800-b891-033653734892",
   "metadata": {},
   "source": [
    "# Insight genertion layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a1b4c2-765e-4447-92dd-33d101d68c1c",
   "metadata": {},
   "source": [
    "creating the insight generation layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "406ae63d-755a-4663-85f8-2ce8febf7258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Insights for First 5 Patients\n",
      "\n",
      "\n",
      "Patient Index: 0\n",
      "--------------------------------------------------\n",
      "{\n",
      "    \"shared_symptoms\": [\n",
      "        \"cough\",\n",
      "        \"dyspnea\",\n",
      "        \"fever\"\n",
      "    ],\n",
      "    \"suggested_treatment\": [\n",
      "        \"intubation\",\n",
      "        \"prone positioning\",\n",
      "        \"supplemental oxygen\"\n",
      "    ],\n",
      "    \"outcome_trend\": \"discharged\",\n",
      "    \"recovery_trend\": \"Not specified\"\n",
      "}\n",
      "\n",
      "Patient Index: 1\n",
      "--------------------------------------------------\n",
      "{\n",
      "    \"shared_symptoms\": [\n",
      "        \"cough\",\n",
      "        \"dyspnea\",\n",
      "        \"fever\"\n",
      "    ],\n",
      "    \"suggested_treatment\": [\n",
      "        \"intubation\",\n",
      "        \"prone positioning\",\n",
      "        \"oxygen therapy\"\n",
      "    ],\n",
      "    \"outcome_trend\": \"discharged\",\n",
      "    \"recovery_trend\": \"Not specified\"\n",
      "}\n",
      "\n",
      "Patient Index: 2\n",
      "--------------------------------------------------\n",
      "{\n",
      "    \"shared_symptoms\": [],\n",
      "    \"suggested_treatment\": [\n",
      "        \"intubation\",\n",
      "        \"prone positioning\",\n",
      "        \"supplemental oxygen\"\n",
      "    ],\n",
      "    \"outcome_trend\": \"discharged\",\n",
      "    \"recovery_trend\": \"Not specified\"\n",
      "}\n",
      "\n",
      "Patient Index: 3\n",
      "--------------------------------------------------\n",
      "{\n",
      "    \"shared_symptoms\": [\n",
      "        \"cough\"\n",
      "    ],\n",
      "    \"suggested_treatment\": [\n",
      "        \"intubation\",\n",
      "        \"prone positioning\",\n",
      "        \"oxygen therapy\"\n",
      "    ],\n",
      "    \"outcome_trend\": \"discharged\",\n",
      "    \"recovery_trend\": \"Not specified\"\n",
      "}\n",
      "\n",
      "Patient Index: 4\n",
      "--------------------------------------------------\n",
      "{\n",
      "    \"shared_symptoms\": [\n",
      "        \"cough\",\n",
      "        \"fever\",\n",
      "        \"dyspnea\"\n",
      "    ],\n",
      "    \"suggested_treatment\": [\n",
      "        \"prone positioning\",\n",
      "        \"supplemental oxygen\",\n",
      "        \"intubation\"\n",
      "    ],\n",
      "    \"outcome_trend\": \"discharged\",\n",
      "    \"recovery_trend\": \"Not specified\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# creating the insight generation layer\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# clinical keywords for symptoms, treatment and otcome\n",
    "SYMPTOM_KEYWORDS = [\n",
    "    \"fever\", \"cough\", \"dry cough\", \"dyspnea\",\n",
    "    \"shortness of breath\", \"hypoxia\", \"fatigue\",\n",
    "    \"chest pain\", \"oxygen desaturation\",\n",
    "    \"tachypnea\", \"respiratory distress\",\n",
    "    \"ards\", \"respiratory failure\", \"oxygen desaturation\", \"hypoxia\",\"hypoxemia\",\"tachypnea\",\n",
    "    \"respiratory distress\", \"acute respiratory distress syndrome\", \"ards\", \"chest tightness\",\n",
    "    \"wheezing\", \"productive cough\", \"hemoptysis\"\n",
    "]\n",
    "\n",
    "TREATMENT_KEYWORDS = [\n",
    "   \"oxygen therapy\",\n",
    "    \"supplemental oxygen\",\n",
    "    \"high flow oxygen\",\n",
    "    \"high flow nasal cannula\",\n",
    "    \"hfno\",\n",
    "    \"non invasive ventilation\",\n",
    "    \"niv\",\n",
    "    \"cpap\",\n",
    "    \"bipap\",\n",
    "    \"mechanical ventilation\",\n",
    "    \"intubation\",\n",
    "    \"ventilator support\",\n",
    "    \"prone positioning\",\n",
    "    \"respiratory support\",\n",
    "]\n",
    "\n",
    "OUTCOME_KEYWORDS = {\n",
    "    \"discharged\": [\"discharged\",\"home discharge\"],\n",
    "    \"rehabilitation\": [\"rehabilitation\",\"rehab clinic\"],\n",
    "    \"critical_monitoring\": [\"icu\",\"intensive care\",\"critical\"]\n",
    "}\n",
    "# similarity based function\n",
    "def retrieve_similar_cases(new_embedding, top_n=5):\n",
    "\n",
    "    global stored_embeddings\n",
    "\n",
    "    if new_embedding.ndim == 1:\n",
    "        new_embedding = new_embedding.reshape(1, -1)\n",
    "\n",
    "    similarity_scores = cosine_similarity(\n",
    "        new_embedding,\n",
    "        stored_embeddings\n",
    "    )[0]\n",
    "\n",
    "    self_index = np.argmax(similarity_scores)\n",
    "    similarity_scores[self_index] = -1\n",
    "\n",
    "    ranked_indices = np.argsort(similarity_scores)[::-1]\n",
    "\n",
    "    return ranked_indices[:top_n]\n",
    "\n",
    "# insight generation function\n",
    "def generate_case_insight(similar_cases, query_text):\n",
    "\n",
    "    similar_texts = patient_df.iloc[similar_cases][\"note_preprocessed\"].tolist()\n",
    "\n",
    "    # ---- Shared Symptoms ----\n",
    "    query_words = set(query_text.split())\n",
    "    symptom_counter = Counter()\n",
    "\n",
    "    for text in similar_texts:\n",
    "        words = set(text.split())\n",
    "        shared = query_words.intersection(words)\n",
    "        shared_symptoms = [w for w in shared if w in SYMPTOM_KEYWORDS]\n",
    "        symptom_counter.update(shared_symptoms)\n",
    "\n",
    "    most_common_symptoms = [sym for sym, _ in symptom_counter.most_common(5)]\n",
    "\n",
    "    # ---- Treatment Extraction ----\n",
    "    treatment_counter = Counter()\n",
    "\n",
    "    for text in similar_texts:\n",
    "        for treatment in TREATMENT_KEYWORDS:\n",
    "            if treatment in text:\n",
    "                treatment_counter.update([treatment])\n",
    "\n",
    "    most_common_treatments = [t for t, _ in treatment_counter.most_common(3)]\n",
    "\n",
    "    # ---- Outcome Trend ----\n",
    "    outcome_trend = \"Not clearly mentioned\"\n",
    "\n",
    "    for outcome, keywords in OUTCOME_KEYWORDS.items():\n",
    "        count = sum(any(k in text for k in keywords) for text in similar_texts)\n",
    "        if count >= 2:\n",
    "            outcome_trend = outcome\n",
    "            break\n",
    "\n",
    "    # ---- Recovery Trend ----\n",
    "    recovery_mentions = [\n",
    "        re.findall(r'\\b\\d+\\s*(day|week|month)s?\\b', text)\n",
    "        for text in similar_texts\n",
    "    ]\n",
    "\n",
    "    recovery_flat = [item for sublist in recovery_mentions for item in sublist]\n",
    "\n",
    "    recovery_trend = \"Not specified\"\n",
    "    if recovery_flat:\n",
    "        recovery_trend = \"Recovery period mentioned in similar cases\"\n",
    "\n",
    "    insight = {\n",
    "        \"shared_symptoms\": most_common_symptoms,\n",
    "        \"suggested_treatment\": most_common_treatments,\n",
    "        \"outcome_trend\": outcome_trend,\n",
    "        \"recovery_trend\": recovery_trend\n",
    "    }\n",
    "\n",
    "    return insight\n",
    "\n",
    "# main function\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"\\nGenerating Insights for First 5 Patients\\n\")\n",
    "\n",
    "    for patient_idx in range(5):\n",
    "\n",
    "        print(f\"\\nPatient Index: {patient_idx}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        query_embedding = stored_embeddings[patient_idx]\n",
    "        query_text = patient_df.iloc[patient_idx][\"note_preprocessed\"]\n",
    "\n",
    "        similar_cases = retrieve_similar_cases(\n",
    "            new_embedding=query_embedding,\n",
    "            top_n=5\n",
    "        )\n",
    "\n",
    "        insight = generate_case_insight(similar_cases, query_text)\n",
    "\n",
    "        print(json.dumps(insight, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82205a5d-af61-462f-9b44-b5c462165b43",
   "metadata": {},
   "source": [
    "created the insight generation layer which provide the similar patients shared symptom, treatment, recovery trend and the outcome trend of the patient in the json file format. We have used the function name provided by you an the outputs are provided in the json file format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71709a71-7750-4343-80fa-811d4e8cc48e",
   "metadata": {},
   "source": [
    "# tresting with input samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860b218f-8233-4996-a138-38a8eb343c44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
