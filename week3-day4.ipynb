{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d62589e8-fec9-4b5c-9523-e306f549f545",
   "metadata": {},
   "source": [
    "# performed precomputing process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ccedab-785a-4148-a58f-3a71765c1d2e",
   "metadata": {},
   "source": [
    "developed a precoputing layer where the preprocessed data is converted embeddings and then found the cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e3e6285-4809-489d-a570-5213872225a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajak\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter full path to preprocessed CSV file:\n",
      ">>  C:\\Users\\rajak\\Downloads\\AI Internship\\newdataset.csv\n",
      "Enter text column name (e.g., note_preprocessed):\n",
      ">>  note_preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings for 600 subjects...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|█████████████████████| 103/103 [00:00<00:00, 292.14it/s, Materializing param=pooler.dense.weight]\n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████| 19/19 [00:20<00:00,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding Matrix Shape: (600, 384)\n",
      "\n",
      "Computing cosine similarity matrix...\n",
      "\n",
      "Cosine Similarity Matrix Shape: (600, 600)\n",
      "\n",
      "Process Completed Successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# precomputing before sharing symptoms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "# model loading\n",
    "def load_embedding_model(model_name=\"all-MiniLM-L6-v2\"):\n",
    "    return SentenceTransformer(model_name)\n",
    "# loading of data and generate embeddings\n",
    "def compute_embeddings(csv_path: str,\n",
    "                       text_column: str,\n",
    "                       limit: int = 600):\n",
    "\n",
    "    # Clean accidental quotes in path\n",
    "    csv_path = csv_path.strip().strip('\"').strip(\"'\")\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    if text_column not in df.columns:\n",
    "        raise ValueError(f\"Column '{text_column}' not found in dataset.\")\n",
    "\n",
    "    # Select first 600 subjects\n",
    "    df_subset = df.head(limit)\n",
    "\n",
    "    texts = df_subset[text_column].astype(str).tolist()\n",
    "\n",
    "    print(f\"\\nGenerating embeddings for {len(texts)} subjects...\\n\")\n",
    "\n",
    "    model = load_embedding_model()\n",
    "\n",
    "    embeddings = model.encode(\n",
    "        texts,\n",
    "        convert_to_numpy=True,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    # IMPORTANT: Normalize embeddings for proper cosine similarity\n",
    "    embeddings = normalize(embeddings, norm=\"l2\")\n",
    "\n",
    "    return df_subset, embeddings\n",
    "# computing cosine similarity\n",
    "def compute_similarity_matrix(embeddings: np.ndarray):\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "    return similarity_matrix\n",
    "\n",
    "# main execution\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Get User Inputs \n",
    "    csv_path = input(\"Enter full path to preprocessed CSV file:\\n>> \")\n",
    "    text_column = input(\"Enter text column name (e.g., note_preprocessed):\\n>> \")\n",
    "\n",
    "    # Step 1: Generate Embeddings \n",
    "    patient_df, stored_embeddings = compute_embeddings(\n",
    "        csv_path=csv_path,\n",
    "        text_column=text_column,\n",
    "        limit=600\n",
    "    )\n",
    "\n",
    "    print(\"\\nEmbedding Matrix Shape:\", stored_embeddings.shape)\n",
    "\n",
    "    # ---- Step 2: Compute Cosine Similarity ----\n",
    "    print(\"\\nComputing cosine similarity matrix...\\n\")\n",
    "\n",
    "    similarity_matrix = compute_similarity_matrix(stored_embeddings)\n",
    "\n",
    "    print(\"Cosine Similarity Matrix Shape:\", similarity_matrix.shape)\n",
    "\n",
    "    print(\"\\nProcess Completed Successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0f46a0-0695-4359-8dad-a99e4a2b13fb",
   "metadata": {},
   "source": [
    "performed the precomputing process. where the prerocessed file have beeen computed embeddings and then find the cosine similarity using the single reusable code for the existing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baf8b39-984a-4800-b891-033653734892",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Insight genertion layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a1b4c2-765e-4447-92dd-33d101d68c1c",
   "metadata": {},
   "source": [
    "creating the insight generation layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "406ae63d-755a-4663-85f8-2ce8febf7258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Insights for First 5 Patients\n",
      "\n",
      "\n",
      "Patient Index: 0\n",
      "--------------------------------------------------\n",
      "{\n",
      "    \"shared_symptoms\": [\n",
      "        \"cough\",\n",
      "        \"dyspnea\",\n",
      "        \"fever\"\n",
      "    ],\n",
      "    \"suggested_treatment\": [\n",
      "        \"intubation\",\n",
      "        \"prone positioning\",\n",
      "        \"supplemental oxygen\"\n",
      "    ],\n",
      "    \"outcome_trend\": \"discharged\",\n",
      "    \"recovery_trend\": \"Not specified\"\n",
      "}\n",
      "\n",
      "Patient Index: 1\n",
      "--------------------------------------------------\n",
      "{\n",
      "    \"shared_symptoms\": [\n",
      "        \"cough\",\n",
      "        \"dyspnea\",\n",
      "        \"fever\"\n",
      "    ],\n",
      "    \"suggested_treatment\": [\n",
      "        \"intubation\",\n",
      "        \"prone positioning\",\n",
      "        \"oxygen therapy\"\n",
      "    ],\n",
      "    \"outcome_trend\": \"discharged\",\n",
      "    \"recovery_trend\": \"Not specified\"\n",
      "}\n",
      "\n",
      "Patient Index: 2\n",
      "--------------------------------------------------\n",
      "{\n",
      "    \"shared_symptoms\": [],\n",
      "    \"suggested_treatment\": [\n",
      "        \"intubation\",\n",
      "        \"prone positioning\",\n",
      "        \"supplemental oxygen\"\n",
      "    ],\n",
      "    \"outcome_trend\": \"discharged\",\n",
      "    \"recovery_trend\": \"Not specified\"\n",
      "}\n",
      "\n",
      "Patient Index: 3\n",
      "--------------------------------------------------\n",
      "{\n",
      "    \"shared_symptoms\": [\n",
      "        \"cough\"\n",
      "    ],\n",
      "    \"suggested_treatment\": [\n",
      "        \"intubation\",\n",
      "        \"prone positioning\",\n",
      "        \"oxygen therapy\"\n",
      "    ],\n",
      "    \"outcome_trend\": \"discharged\",\n",
      "    \"recovery_trend\": \"Not specified\"\n",
      "}\n",
      "\n",
      "Patient Index: 4\n",
      "--------------------------------------------------\n",
      "{\n",
      "    \"shared_symptoms\": [\n",
      "        \"cough\",\n",
      "        \"dyspnea\",\n",
      "        \"fever\"\n",
      "    ],\n",
      "    \"suggested_treatment\": [\n",
      "        \"prone positioning\",\n",
      "        \"supplemental oxygen\",\n",
      "        \"intubation\"\n",
      "    ],\n",
      "    \"outcome_trend\": \"discharged\",\n",
      "    \"recovery_trend\": \"Not specified\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# creating the insight generation layer\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# clinical keywords for symptoms, treatment and otcome\n",
    "SYMPTOM_KEYWORDS = [\n",
    "    \"fever\", \"cough\", \"dry cough\", \"dyspnea\",\n",
    "    \"shortness of breath\", \"hypoxia\", \"fatigue\",\n",
    "    \"chest pain\", \"oxygen desaturation\",\n",
    "    \"tachypnea\", \"respiratory distress\",\n",
    "    \"ards\", \"respiratory failure\", \"oxygen desaturation\", \"hypoxia\",\"hypoxemia\",\"tachypnea\",\n",
    "    \"respiratory distress\", \"acute respiratory distress syndrome\", \"ards\", \"chest tightness\",\n",
    "    \"wheezing\", \"productive cough\", \"hemoptysis\"\n",
    "]\n",
    "\n",
    "TREATMENT_KEYWORDS = [\n",
    "   \"oxygen therapy\",\n",
    "    \"supplemental oxygen\",\n",
    "    \"high flow oxygen\",\n",
    "    \"high flow nasal cannula\",\n",
    "    \"hfno\",\n",
    "    \"non invasive ventilation\",\n",
    "    \"niv\",\n",
    "    \"cpap\",\n",
    "    \"bipap\",\n",
    "    \"mechanical ventilation\",\n",
    "    \"intubation\",\n",
    "    \"ventilator support\",\n",
    "    \"prone positioning\",\n",
    "    \"respiratory support\",\n",
    "]\n",
    "\n",
    "OUTCOME_KEYWORDS = {\n",
    "    \"discharged\": [\"discharged\",\"home discharge\"],\n",
    "    \"rehabilitation\": [\"rehabilitation\",\"rehab clinic\"],\n",
    "    \"critical_monitoring\": [\"icu\",\"intensive care\",\"critical\"]\n",
    "}\n",
    "# similarity based function\n",
    "def retrieve_similar_cases(new_embedding, top_n=5):\n",
    "\n",
    "    global stored_embeddings\n",
    "\n",
    "    if new_embedding.ndim == 1:\n",
    "        new_embedding = new_embedding.reshape(1, -1)\n",
    "\n",
    "    similarity_scores = cosine_similarity(\n",
    "        new_embedding,\n",
    "        stored_embeddings\n",
    "    )[0]\n",
    "\n",
    "    self_index = np.argmax(similarity_scores)\n",
    "    similarity_scores[self_index] = -1\n",
    "\n",
    "    ranked_indices = np.argsort(similarity_scores)[::-1]\n",
    "\n",
    "    return ranked_indices[:top_n]\n",
    "\n",
    "# insight generation function\n",
    "def generate_case_insight(similar_cases, query_text):\n",
    "\n",
    "    similar_texts = patient_df.iloc[similar_cases][\"note_preprocessed\"].tolist()\n",
    "\n",
    "    # ---- Shared Symptoms ----\n",
    "    query_words = set(query_text.split())\n",
    "    symptom_counter = Counter()\n",
    "\n",
    "    for text in similar_texts:\n",
    "        words = set(text.split())\n",
    "        shared = query_words.intersection(words)\n",
    "        shared_symptoms = [w for w in shared if w in SYMPTOM_KEYWORDS]\n",
    "        symptom_counter.update(shared_symptoms)\n",
    "\n",
    "    most_common_symptoms = [sym for sym, _ in symptom_counter.most_common(5)]\n",
    "\n",
    "    # ---- Treatment Extraction ----\n",
    "    treatment_counter = Counter()\n",
    "\n",
    "    for text in similar_texts:\n",
    "        for treatment in TREATMENT_KEYWORDS:\n",
    "            if treatment in text:\n",
    "                treatment_counter.update([treatment])\n",
    "\n",
    "    most_common_treatments = [t for t, _ in treatment_counter.most_common(3)]\n",
    "\n",
    "    # ---- Outcome Trend ----\n",
    "    outcome_trend = \"Not clearly mentioned\"\n",
    "\n",
    "    for outcome, keywords in OUTCOME_KEYWORDS.items():\n",
    "        count = sum(any(k in text for k in keywords) for text in similar_texts)\n",
    "        if count >= 2:\n",
    "            outcome_trend = outcome\n",
    "            break\n",
    "\n",
    "    # ---- Recovery Trend ----\n",
    "    recovery_mentions = [\n",
    "        re.findall(r'\\b\\d+\\s*(day|week|month)s?\\b', text)\n",
    "        for text in similar_texts\n",
    "    ]\n",
    "\n",
    "    recovery_flat = [item for sublist in recovery_mentions for item in sublist]\n",
    "\n",
    "    recovery_trend = \"Not specified\"\n",
    "    if recovery_flat:\n",
    "        recovery_trend = \"Recovery period mentioned in similar cases\"\n",
    "\n",
    "    insight = {\n",
    "        \"shared_symptoms\": most_common_symptoms,\n",
    "        \"suggested_treatment\": most_common_treatments,\n",
    "        \"outcome_trend\": outcome_trend,\n",
    "        \"recovery_trend\": recovery_trend\n",
    "    }\n",
    "\n",
    "    return insight\n",
    "\n",
    "# main function\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"\\nGenerating Insights for First 5 Patients\\n\")\n",
    "\n",
    "    for patient_idx in range(5):\n",
    "\n",
    "        print(f\"\\nPatient Index: {patient_idx}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        query_embedding = stored_embeddings[patient_idx]\n",
    "        query_text = patient_df.iloc[patient_idx][\"note_preprocessed\"]\n",
    "\n",
    "        similar_cases = retrieve_similar_cases(\n",
    "            new_embedding=query_embedding,\n",
    "            top_n=5\n",
    "        )\n",
    "\n",
    "        insight = generate_case_insight(similar_cases, query_text)\n",
    "\n",
    "        print(json.dumps(insight, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82205a5d-af61-462f-9b44-b5c462165b43",
   "metadata": {},
   "source": [
    "created the insight generation layer which provide the similar patients shared symptom, treatment, recovery trend and the outcome trend of the patient in the json file format. We have used the function name provided by you an the outputs are provided in the json file format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71709a71-7750-4343-80fa-811d4e8cc48e",
   "metadata": {},
   "source": [
    "# tresting with input samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec44f81d-2565-46a5-984a-9fca0aad2b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter symptoms:\n",
      ">>  fever, dry cough, shortness of breath\n",
      "\n",
      "Enter clinical notes:\n",
      ">>  Patient admitted with four day history of fever and persistent dry cough associated with progressive shortness of breath. Oxygen saturation mildly reduced requiring supplemental oxygen therapy. No prior chronic respiratory illness reported.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|█████████████████████| 103/103 [00:00<00:00, 550.88it/s, Materializing param=pooler.dense.weight]\n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Output (JSON Format):\n",
      "\n",
      "{\n",
      "    \"input_processed\": \"fever dry cough shortness breath patient admitted with day history fever persistent dry cough associated with progressive shortness breath oxygen saturation mildly reduced requiring supplemental oxygen therapy no prior chronic respiratory illness reported\",\n",
      "    \"nearest_similar_patients\": [\n",
      "        {\n",
      "            \"patient_id\": 60,\n",
      "            \"similarity_score\": 0.6396\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 59,\n",
      "            \"similarity_score\": 0.598\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 9,\n",
      "            \"similarity_score\": 0.572\n",
      "        }\n",
      "    ],\n",
      "    \"most_similar_patient_insight\": {\n",
      "        \"shared_symptoms\": [\n",
      "            \"cough\",\n",
      "            \"fever\"\n",
      "        ],\n",
      "        \"treatments\": [\n",
      "            \"oxygen therapy\",\n",
      "            \"high flow oxygen\",\n",
      "            \"methylprednisolone\",\n",
      "            \"azithromycin\"\n",
      "        ],\n",
      "        \"outcome\": \"discharged\",\n",
      "        \"recovery_trend\": \"Not specified\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# testing the insight generation layer\n",
    "\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.preprocessing import normalize\n",
    "# clinical keywords\n",
    "SYMPTOM_KEYWORDS = [\n",
    "    \"fever\",\"dry cough\",\"cough\",\"fatigue\",\"weakness\",\n",
    "    \"dyspnea\",\"shortness of breath\",\"breathlessness\",\n",
    "    \"oxygen desaturation\",\"hypoxia\",\"tachypnea\",\n",
    "    \"respiratory distress\",\"acute respiratory distress syndrome\",\n",
    "    \"chest pain\",\"headache\",\"nausea\",\"vomiting\",\n",
    "    \"diarrhea\",\"loss of smell\",\"anosmia\",\"loss of taste\",\n",
    "    \"ageusia\",\"confusion\",\"delirium\",\"cyanosis\",\n",
    "    \"respiratory failure\",\"shock\"\n",
    "]\n",
    "TREATMENT_KEYWORDS = [\n",
    "    \"oxygen therapy\",\"supplemental oxygen\",\"high flow oxygen\",\n",
    "    \"non invasive ventilation\",\"mechanical ventilation\",\n",
    "    \"intubation\",\"ventilator support\",\"prone positioning\",\n",
    "    \"remdesivir\",\"antiviral therapy\",\"dexamethasone\",\n",
    "    \"methylprednisolone\",\"steroid therapy\",\n",
    "    \"antibiotics\",\"azithromycin\",\"ceftriaxone\",\n",
    "    \"heparin\",\"anticoagulation therapy\",\n",
    "    \"bronchodilator\",\"nebulization\",\n",
    "    \"physiotherapy\",\"pulmonary rehabilitation\",\n",
    "    \"breathing exercise\",\"icu admission\",\n",
    "    \"critical care monitoring\"\n",
    "]\n",
    "\n",
    "OUTCOME_KEYWORDS = {\n",
    "    \"discharged\": [\"discharged\",\"home discharge\"],\n",
    "    \"rehabilitation\": [\"rehabilitation\",\"rehab clinic\"],\n",
    "    \"critical_monitoring\": [\"icu\",\"intensive care\",\"critical\"]\n",
    "}\n",
    "# pre-processing of the data\n",
    "IMPORTANT_WORDS = {\"no\",\"not\",\"without\",\"with\",\"before\",\"after\",\"during\",\"since\"}\n",
    "CUSTOM_STOPWORDS = ENGLISH_STOP_WORDS.difference(IMPORTANT_WORDS)\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in CUSTOM_STOPWORDS]\n",
    "\n",
    "    return \" \".join(words)\n",
    "# loading the embedding module\n",
    "def load_embedding_model():\n",
    "    return SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "# similarity case module\n",
    "def retrieve_similar_cases(new_embedding, top_n=3):\n",
    "\n",
    "    global stored_embeddings\n",
    "\n",
    "    if new_embedding.ndim == 1:\n",
    "        new_embedding = new_embedding.reshape(1, -1)\n",
    "\n",
    "    new_embedding = normalize(new_embedding, norm=\"l2\")\n",
    "\n",
    "    similarity_scores = cosine_similarity(\n",
    "        new_embedding,\n",
    "        stored_embeddings\n",
    "    )[0]\n",
    "\n",
    "    ranked_indices = np.argsort(similarity_scores)[::-1]\n",
    "\n",
    "    top_indices = ranked_indices[:top_n]\n",
    "    top_scores = similarity_scores[top_indices]\n",
    "\n",
    "    return top_indices, top_scores\n",
    "\n",
    "# main function\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #  USER INPUT \n",
    "    symptoms_input = input(\"Enter symptoms:\\n>> \")\n",
    "    notes_input = input(\"\\nEnter clinical notes:\\n>> \")\n",
    "\n",
    "    combined_input = symptoms_input + \" \" + notes_input\n",
    "    processed_text = preprocess_text(combined_input)\n",
    "\n",
    "    #  EMBEDDING \n",
    "    model = load_embedding_model()\n",
    "\n",
    "    query_embedding = model.encode(\n",
    "        [processed_text],\n",
    "        convert_to_numpy=True\n",
    "    )[0]\n",
    "\n",
    "    # RETRIEVE TOP 3 \n",
    "    top_indices, top_scores = retrieve_similar_cases(\n",
    "        new_embedding=query_embedding,\n",
    "        top_n=3\n",
    "    )\n",
    "\n",
    "    #  MOST SIMILAR PATIENT \n",
    "    most_similar_index = top_indices[0]\n",
    "    most_similar_text = patient_df.iloc[most_similar_index][\"note_preprocessed\"]\n",
    "\n",
    "    # SHARED SYMPTOMS \n",
    "    query_words = set(processed_text.split())\n",
    "    similar_words = set(most_similar_text.split())\n",
    "\n",
    "    shared_symptoms = [\n",
    "        word for word in query_words.intersection(similar_words)\n",
    "        if word in SYMPTOM_KEYWORDS\n",
    "    ]\n",
    "\n",
    "    # TREATMENT EXTRACTION \n",
    "    treatments_found = [\n",
    "        treatment for treatment in TREATMENT_KEYWORDS\n",
    "        if re.search(rf\"\\b{re.escape(treatment)}\\b\", most_similar_text)\n",
    "    ]\n",
    "\n",
    "    #  OUTCOME EXTRACTION \n",
    "    outcome = \"Not clearly mentioned\"\n",
    "\n",
    "    for key, keywords in OUTCOME_KEYWORDS.items():\n",
    "        if any(k in most_similar_text for k in keywords):\n",
    "            outcome = key\n",
    "            break\n",
    "\n",
    "    #  RECOVERY TREND \n",
    "    recovery_matches = re.findall(\n",
    "        r'\\b\\d+\\s*(day|week|month)s?\\b',\n",
    "        most_similar_text\n",
    "    )\n",
    "\n",
    "    recovery_trend = \"Not specified\"\n",
    "    if recovery_matches:\n",
    "        recovery_trend = \"Recovery duration mentioned in similar case\"\n",
    "\n",
    "    #  JSON OUTPUT FORMATTING\n",
    "    result = {\n",
    "        \"input_processed\": processed_text,\n",
    "        \"nearest_similar_patients\": [\n",
    "            {\n",
    "                \"patient_id\": patient_df.iloc[idx][\"patient_uid\"]\n",
    "                if \"patient_uid\" in patient_df.columns else int(idx),\n",
    "                \"similarity_score\": round(float(score), 4)\n",
    "            }\n",
    "            for idx, score in zip(top_indices, top_scores)\n",
    "        ],\n",
    "        \"most_similar_patient_insight\": {\n",
    "            \"shared_symptoms\": shared_symptoms,\n",
    "            \"treatments\": treatments_found,\n",
    "            \"outcome\": outcome,\n",
    "            \"recovery_trend\": recovery_trend\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(\"\\nFinal Output (JSON Format):\\n\")\n",
    "    print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136bfc72-b7b2-40d6-af60-a7c2b35e5a27",
   "metadata": {},
   "source": [
    "tested the developed insight generation module with the new input sample. This insight generation module finds the top three similar patients, most similar shared symptoms, treatment, outcome and recovery trend in the JSON file format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761b0a04-69e6-4ccc-bc0f-997ca9c20c8f",
   "metadata": {},
   "source": [
    "testing with the input sample 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb74c800-eb31-4a3c-b790-fb61553d4d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter symptoms:\n",
      ">>  oxygen desaturation, dyspnea, fatigue\n",
      "\n",
      "Enter clinical notes:\n",
      ">>  Elderly male presented with worsening dyspnea and oxygen desaturation over the past two days. Patient required high flow oxygen support and close monitoring in intensive care unit. Fatigue and respiratory distress observed during minimal exertion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|█████████████████████| 103/103 [00:00<00:00, 249.14it/s, Materializing param=pooler.dense.weight]\n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Output (JSON Format):\n",
      "\n",
      "{\n",
      "    \"input_processed\": \"oxygen desaturation dyspnea fatigue elderly male presented with worsening dyspnea oxygen desaturation past days patient required high flow oxygen support close monitoring intensive care unit fatigue respiratory distress observed during minimal exertion\",\n",
      "    \"nearest_similar_patients\": [\n",
      "        {\n",
      "            \"patient_id\": 9,\n",
      "            \"similarity_score\": 0.6081\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 8,\n",
      "            \"similarity_score\": 0.5709\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 6,\n",
      "            \"similarity_score\": 0.5533\n",
      "        }\n",
      "    ],\n",
      "    \"most_similar_patient_insight\": {\n",
      "        \"shared_symptoms\": [\n",
      "            \"dyspnea\",\n",
      "            \"fatigue\"\n",
      "        ],\n",
      "        \"treatments\": [\n",
      "            \"oxygen therapy\"\n",
      "        ],\n",
      "        \"outcome\": \"critical_monitoring\",\n",
      "        \"recovery_trend\": \"Not specified\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# testing the insight generation layer\n",
    "\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.preprocessing import normalize\n",
    "# clinical keywords\n",
    "SYMPTOM_KEYWORDS = [\n",
    "    \"fever\",\"dry cough\",\"cough\",\"fatigue\",\"weakness\",\n",
    "    \"dyspnea\",\"shortness of breath\",\"breathlessness\",\n",
    "    \"oxygen desaturation\",\"hypoxia\",\"tachypnea\",\n",
    "    \"respiratory distress\",\"acute respiratory distress syndrome\",\n",
    "    \"chest pain\",\"headache\",\"nausea\",\"vomiting\",\n",
    "    \"diarrhea\",\"loss of smell\",\"anosmia\",\"loss of taste\",\n",
    "    \"ageusia\",\"confusion\",\"delirium\",\"cyanosis\",\n",
    "    \"respiratory failure\",\"shock\"\n",
    "]\n",
    "TREATMENT_KEYWORDS = [\n",
    "    \"oxygen therapy\",\"supplemental oxygen\",\"high flow oxygen\",\n",
    "    \"non invasive ventilation\",\"mechanical ventilation\",\n",
    "    \"intubation\",\"ventilator support\",\"prone positioning\",\n",
    "    \"remdesivir\",\"antiviral therapy\",\"dexamethasone\",\n",
    "    \"methylprednisolone\",\"steroid therapy\",\n",
    "    \"antibiotics\",\"azithromycin\",\"ceftriaxone\",\n",
    "    \"heparin\",\"anticoagulation therapy\",\n",
    "    \"bronchodilator\",\"nebulization\",\n",
    "    \"physiotherapy\",\"pulmonary rehabilitation\",\n",
    "    \"breathing exercise\",\"icu admission\",\n",
    "    \"critical care monitoring\"\n",
    "]\n",
    "\n",
    "OUTCOME_KEYWORDS = {\n",
    "    \"discharged\": [\"discharged\",\"home discharge\"],\n",
    "    \"rehabilitation\": [\"rehabilitation\",\"rehab clinic\"],\n",
    "    \"critical_monitoring\": [\"icu\",\"intensive care\",\"critical\"]\n",
    "}\n",
    "# pre-processing of the data\n",
    "IMPORTANT_WORDS = {\"no\",\"not\",\"without\",\"with\",\"before\",\"after\",\"during\",\"since\"}\n",
    "CUSTOM_STOPWORDS = ENGLISH_STOP_WORDS.difference(IMPORTANT_WORDS)\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in CUSTOM_STOPWORDS]\n",
    "\n",
    "    return \" \".join(words)\n",
    "# loading the embedding module\n",
    "def load_embedding_model():\n",
    "    return SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "# similarity case module\n",
    "def retrieve_similar_cases(new_embedding, top_n=3):\n",
    "\n",
    "    global stored_embeddings\n",
    "\n",
    "    if new_embedding.ndim == 1:\n",
    "        new_embedding = new_embedding.reshape(1, -1)\n",
    "\n",
    "    new_embedding = normalize(new_embedding, norm=\"l2\")\n",
    "\n",
    "    similarity_scores = cosine_similarity(\n",
    "        new_embedding,\n",
    "        stored_embeddings\n",
    "    )[0]\n",
    "\n",
    "    ranked_indices = np.argsort(similarity_scores)[::-1]\n",
    "\n",
    "    top_indices = ranked_indices[:top_n]\n",
    "    top_scores = similarity_scores[top_indices]\n",
    "\n",
    "    return top_indices, top_scores\n",
    "\n",
    "# main function\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #  USER INPUT \n",
    "    symptoms_input = input(\"Enter symptoms:\\n>> \")\n",
    "    notes_input = input(\"\\nEnter clinical notes:\\n>> \")\n",
    "\n",
    "    combined_input = symptoms_input + \" \" + notes_input\n",
    "    processed_text = preprocess_text(combined_input)\n",
    "\n",
    "    #  EMBEDDING \n",
    "    model = load_embedding_model()\n",
    "\n",
    "    query_embedding = model.encode(\n",
    "        [processed_text],\n",
    "        convert_to_numpy=True\n",
    "    )[0]\n",
    "\n",
    "    # RETRIEVE TOP 3 \n",
    "    top_indices, top_scores = retrieve_similar_cases(\n",
    "        new_embedding=query_embedding,\n",
    "        top_n=3\n",
    "    )\n",
    "\n",
    "    #  MOST SIMILAR PATIENT \n",
    "    most_similar_index = top_indices[0]\n",
    "    most_similar_text = patient_df.iloc[most_similar_index][\"note_preprocessed\"]\n",
    "\n",
    "    # SHARED SYMPTOMS \n",
    "    query_words = set(processed_text.split())\n",
    "    similar_words = set(most_similar_text.split())\n",
    "\n",
    "    shared_symptoms = [\n",
    "        word for word in query_words.intersection(similar_words)\n",
    "        if word in SYMPTOM_KEYWORDS\n",
    "    ]\n",
    "\n",
    "    # TREATMENT EXTRACTION \n",
    "    treatments_found = [\n",
    "        treatment for treatment in TREATMENT_KEYWORDS\n",
    "        if re.search(rf\"\\b{re.escape(treatment)}\\b\", most_similar_text)\n",
    "    ]\n",
    "\n",
    "    #  OUTCOME EXTRACTION \n",
    "    outcome = \"Not clearly mentioned\"\n",
    "\n",
    "    for key, keywords in OUTCOME_KEYWORDS.items():\n",
    "        if any(k in most_similar_text for k in keywords):\n",
    "            outcome = key\n",
    "            break\n",
    "\n",
    "    #  RECOVERY TREND \n",
    "    recovery_matches = re.findall(\n",
    "        r'\\b\\d+\\s*(day|week|month)s?\\b',\n",
    "        most_similar_text\n",
    "    )\n",
    "\n",
    "    recovery_trend = \"Not specified\"\n",
    "    if recovery_matches:\n",
    "        recovery_trend = \"Recovery duration mentioned in similar case\"\n",
    "\n",
    "    #  JSON OUTPUT FORMATTING\n",
    "    result = {\n",
    "        \"input_processed\": processed_text,\n",
    "        \"nearest_similar_patients\": [\n",
    "            {\n",
    "                \"patient_id\": patient_df.iloc[idx][\"patient_uid\"]\n",
    "                if \"patient_uid\" in patient_df.columns else int(idx),\n",
    "                \"similarity_score\": round(float(score), 4)\n",
    "            }\n",
    "            for idx, score in zip(top_indices, top_scores)\n",
    "        ],\n",
    "        \"most_similar_patient_insight\": {\n",
    "            \"shared_symptoms\": shared_symptoms,\n",
    "            \"treatments\": treatments_found,\n",
    "            \"outcome\": outcome,\n",
    "            \"recovery_trend\": recovery_trend\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(\"\\nFinal Output (JSON Format):\\n\")\n",
    "    print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16032f7c-108e-4ae9-acff-2f9d0c968b6a",
   "metadata": {},
   "source": [
    "For sample 2, the developed insight generation model also produces the proper output conists of the top 3 similar patients with a more similar score, the treatment suggestion, outcome, and recovery trend of the new patient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d026570-a853-4725-be64-f1930e165134",
   "metadata": {},
   "source": [
    "Testing with the input sample 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e294db7-41fb-4554-862b-6ccda2245141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter symptoms:\n",
      ">>  fever, headache, loss of smell\n",
      "\n",
      "Enter clinical notes:\n",
      ">>  Patient reported low grade fever with persistent headache and recent loss of smell. Respiratory status stable without need for mechanical ventilation. Managed conservatively with monitoring and supportive care.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|█████████████████████| 103/103 [00:00<00:00, 294.49it/s, Materializing param=pooler.dense.weight]\n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Output (JSON Format):\n",
      "\n",
      "{\n",
      "    \"input_processed\": \"fever headache loss smell patient reported low grade fever with persistent headache recent loss smell respiratory status stable without need mechanical ventilation managed conservatively with monitoring supportive care\",\n",
      "    \"nearest_similar_patients\": [\n",
      "        {\n",
      "            \"patient_id\": 188,\n",
      "            \"similarity_score\": 0.5236\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 7,\n",
      "            \"similarity_score\": 0.5226\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 186,\n",
      "            \"similarity_score\": 0.495\n",
      "        }\n",
      "    ],\n",
      "    \"most_similar_patient_insight\": {\n",
      "        \"shared_symptoms\": [\n",
      "            \"headache\",\n",
      "            \"fever\"\n",
      "        ],\n",
      "        \"treatments\": [\n",
      "            \"mechanical ventilation\",\n",
      "            \"methylprednisolone\"\n",
      "        ],\n",
      "        \"outcome\": \"discharged\",\n",
      "        \"recovery_trend\": \"Not specified\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# testing the insight generation layer\n",
    "\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.preprocessing import normalize\n",
    "# clinical keywords\n",
    "SYMPTOM_KEYWORDS = [\n",
    "    \"fever\",\"dry cough\",\"cough\",\"fatigue\",\"weakness\",\n",
    "    \"dyspnea\",\"shortness of breath\",\"breathlessness\",\n",
    "    \"oxygen desaturation\",\"hypoxia\",\"tachypnea\",\n",
    "    \"respiratory distress\",\"acute respiratory distress syndrome\",\n",
    "    \"chest pain\",\"headache\",\"nausea\",\"vomiting\",\n",
    "    \"diarrhea\",\"loss of smell\",\"anosmia\",\"loss of taste\",\n",
    "    \"ageusia\",\"confusion\",\"delirium\",\"cyanosis\",\n",
    "    \"respiratory failure\",\"shock\"\n",
    "]\n",
    "TREATMENT_KEYWORDS = [\n",
    "    \"oxygen therapy\",\"supplemental oxygen\",\"high flow oxygen\",\n",
    "    \"non invasive ventilation\",\"mechanical ventilation\",\n",
    "    \"intubation\",\"ventilator support\",\"prone positioning\",\n",
    "    \"remdesivir\",\"antiviral therapy\",\"dexamethasone\",\n",
    "    \"methylprednisolone\",\"steroid therapy\",\n",
    "    \"antibiotics\",\"azithromycin\",\"ceftriaxone\",\n",
    "    \"heparin\",\"anticoagulation therapy\",\n",
    "    \"bronchodilator\",\"nebulization\",\n",
    "    \"physiotherapy\",\"pulmonary rehabilitation\",\n",
    "    \"breathing exercise\",\"icu admission\",\n",
    "    \"critical care monitoring\"\n",
    "]\n",
    "\n",
    "OUTCOME_KEYWORDS = {\n",
    "    \"discharged\": [\"discharged\",\"home discharge\"],\n",
    "    \"rehabilitation\": [\"rehabilitation\",\"rehab clinic\"],\n",
    "    \"critical_monitoring\": [\"icu\",\"intensive care\",\"critical\"]\n",
    "}\n",
    "# pre-processing of the data\n",
    "IMPORTANT_WORDS = {\"no\",\"not\",\"without\",\"with\",\"before\",\"after\",\"during\",\"since\"}\n",
    "CUSTOM_STOPWORDS = ENGLISH_STOP_WORDS.difference(IMPORTANT_WORDS)\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in CUSTOM_STOPWORDS]\n",
    "\n",
    "    return \" \".join(words)\n",
    "# loading the embedding module\n",
    "def load_embedding_model():\n",
    "    return SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "# similarity case module\n",
    "def retrieve_similar_cases(new_embedding, top_n=3):\n",
    "\n",
    "    global stored_embeddings\n",
    "\n",
    "    if new_embedding.ndim == 1:\n",
    "        new_embedding = new_embedding.reshape(1, -1)\n",
    "\n",
    "    new_embedding = normalize(new_embedding, norm=\"l2\")\n",
    "\n",
    "    similarity_scores = cosine_similarity(\n",
    "        new_embedding,\n",
    "        stored_embeddings\n",
    "    )[0]\n",
    "\n",
    "    ranked_indices = np.argsort(similarity_scores)[::-1]\n",
    "\n",
    "    top_indices = ranked_indices[:top_n]\n",
    "    top_scores = similarity_scores[top_indices]\n",
    "\n",
    "    return top_indices, top_scores\n",
    "\n",
    "# main function\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #  USER INPUT \n",
    "    symptoms_input = input(\"Enter symptoms:\\n>> \")\n",
    "    notes_input = input(\"\\nEnter clinical notes:\\n>> \")\n",
    "\n",
    "    combined_input = symptoms_input + \" \" + notes_input\n",
    "    processed_text = preprocess_text(combined_input)\n",
    "\n",
    "    #  EMBEDDING \n",
    "    model = load_embedding_model()\n",
    "\n",
    "    query_embedding = model.encode(\n",
    "        [processed_text],\n",
    "        convert_to_numpy=True\n",
    "    )[0]\n",
    "\n",
    "    # RETRIEVE TOP 3 \n",
    "    top_indices, top_scores = retrieve_similar_cases(\n",
    "        new_embedding=query_embedding,\n",
    "        top_n=3\n",
    "    )\n",
    "\n",
    "    #  MOST SIMILAR PATIENT \n",
    "    most_similar_index = top_indices[0]\n",
    "    most_similar_text = patient_df.iloc[most_similar_index][\"note_preprocessed\"]\n",
    "\n",
    "    # SHARED SYMPTOMS \n",
    "    query_words = set(processed_text.split())\n",
    "    similar_words = set(most_similar_text.split())\n",
    "\n",
    "    shared_symptoms = [\n",
    "        word for word in query_words.intersection(similar_words)\n",
    "        if word in SYMPTOM_KEYWORDS\n",
    "    ]\n",
    "\n",
    "    # TREATMENT EXTRACTION \n",
    "    treatments_found = [\n",
    "        treatment for treatment in TREATMENT_KEYWORDS\n",
    "        if re.search(rf\"\\b{re.escape(treatment)}\\b\", most_similar_text)\n",
    "    ]\n",
    "\n",
    "    #  OUTCOME EXTRACTION \n",
    "    outcome = \"Not clearly mentioned\"\n",
    "\n",
    "    for key, keywords in OUTCOME_KEYWORDS.items():\n",
    "        if any(k in most_similar_text for k in keywords):\n",
    "            outcome = key\n",
    "            break\n",
    "\n",
    "    #  RECOVERY TREND \n",
    "    recovery_matches = re.findall(\n",
    "        r'\\b\\d+\\s*(day|week|month)s?\\b',\n",
    "        most_similar_text\n",
    "    )\n",
    "\n",
    "    recovery_trend = \"Not specified\"\n",
    "    if recovery_matches:\n",
    "        recovery_trend = \"Recovery duration mentioned in similar case\"\n",
    "\n",
    "    #  JSON OUTPUT FORMATTING\n",
    "    result = {\n",
    "        \"input_processed\": processed_text,\n",
    "        \"nearest_similar_patients\": [\n",
    "            {\n",
    "                \"patient_id\": patient_df.iloc[idx][\"patient_uid\"]\n",
    "                if \"patient_uid\" in patient_df.columns else int(idx),\n",
    "                \"similarity_score\": round(float(score), 4)\n",
    "            }\n",
    "            for idx, score in zip(top_indices, top_scores)\n",
    "        ],\n",
    "        \"most_similar_patient_insight\": {\n",
    "            \"shared_symptoms\": shared_symptoms,\n",
    "            \"treatments\": treatments_found,\n",
    "            \"outcome\": outcome,\n",
    "            \"recovery_trend\": recovery_trend\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(\"\\nFinal Output (JSON Format):\\n\")\n",
    "    print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16936e7-0f57-4fb7-8be4-d1e74a61378d",
   "metadata": {},
   "source": [
    "The generated reusable code have been successfully tested with the new three sample patients. for the tested samples it efficiently produces the top three similar patients, shared symptoms, treatment, outcome and recovery trend have been produced for the sample input."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
