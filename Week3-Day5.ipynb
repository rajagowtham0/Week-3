{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d72a1084-cf71-44da-8499-c5ae4aa45e81",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Precomputing of exisiting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d42b8a6d-a451-4491-b503-315a32e499e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajak\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter full path to preprocessed CSV file:\n",
      ">>  C:\\Users\\rajak\\Downloads\\AI Internship\\newdataset.csv\n",
      "Enter text column name (e.g., note_preprocessed):\n",
      ">>  note_preprocessed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings for 600 subjects...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 306.17it/s, Materializing param=pooler.dense.weight]\n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:31<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding Matrix Shape: (600, 384)\n",
      "\n",
      "Computing cosine similarity matrix...\n",
      "\n",
      "Cosine Similarity Matrix Shape: (600, 600)\n",
      "\n",
      "Process Completed Successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# precomputing before sharing symptoms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "# model loading\n",
    "def load_embedding_model(model_name=\"all-MiniLM-L6-v2\"):\n",
    "    return SentenceTransformer(model_name)\n",
    "# loading of data and generate embeddings\n",
    "def compute_embeddings(csv_path: str,\n",
    "                       text_column: str,\n",
    "                       limit: int = 600):\n",
    "\n",
    "    # Clean accidental quotes in path\n",
    "    csv_path = csv_path.strip().strip('\"').strip(\"'\")\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    if text_column not in df.columns:\n",
    "        raise ValueError(f\"Column '{text_column}' not found in dataset.\")\n",
    "\n",
    "    # Select first 600 subjects\n",
    "    df_subset = df.head(limit)\n",
    "\n",
    "    texts = df_subset[text_column].astype(str).tolist()\n",
    "\n",
    "    print(f\"\\nGenerating embeddings for {len(texts)} subjects...\\n\")\n",
    "\n",
    "    model = load_embedding_model()\n",
    "\n",
    "    embeddings = model.encode(\n",
    "        texts,\n",
    "        convert_to_numpy=True,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    # IMPORTANT: Normalize embeddings for proper cosine similarity\n",
    "    embeddings = normalize(embeddings, norm=\"l2\")\n",
    "\n",
    "    return df_subset, embeddings\n",
    "# computing cosine similarity\n",
    "def compute_similarity_matrix(embeddings: np.ndarray):\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "    return similarity_matrix\n",
    "\n",
    "# main execution\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Get User Inputs \n",
    "    csv_path = input(\"Enter full path to preprocessed CSV file:\\n>> \")\n",
    "    text_column = input(\"Enter text column name (e.g., note_preprocessed):\\n>> \")\n",
    "\n",
    "    # Step 1: Generate Embeddings \n",
    "    patient_df, stored_embeddings = compute_embeddings(\n",
    "        csv_path=csv_path,\n",
    "        text_column=text_column,\n",
    "        limit=600\n",
    "    )\n",
    "\n",
    "    print(\"\\nEmbedding Matrix Shape:\", stored_embeddings.shape)\n",
    "\n",
    "    # ---- Step 2: Compute Cosine Similarity ----\n",
    "    print(\"\\nComputing cosine similarity matrix...\\n\")\n",
    "\n",
    "    similarity_matrix = compute_similarity_matrix(stored_embeddings)\n",
    "\n",
    "    print(\"Cosine Similarity Matrix Shape:\", similarity_matrix.shape)\n",
    "\n",
    "    print(\"\\nProcess Completed Successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8c4e47-cd38-4ef2-b861-8ffd20e368be",
   "metadata": {},
   "source": [
    "completed the precomputing of the existing data for our end to end ccms stimulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef103c14-d9fe-439f-82f4-ee617fa7ce20",
   "metadata": {},
   "source": [
    "# End to end ccms stimulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb0e014-a604-445b-8d4c-db4b1d81ca06",
   "metadata": {},
   "source": [
    "at first end to end ccms stimulation has been carried out for the first top three existing patients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "801b4153-372f-46ac-92e7-c2b140407f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating insights for First 3 Subjects\n",
      "\n",
      "\n",
      "===== Patient Index 0 =====\n",
      "\n",
      "{\n",
      "    \"query_patient_id\": 0,\n",
      "    \"similar_cases\": [\n",
      "        {\n",
      "            \"patient_id\": 1,\n",
      "            \"similarity_score\": 0.854\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 6,\n",
      "            \"similarity_score\": 0.8378\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 4,\n",
      "            \"similarity_score\": 0.8367\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 2,\n",
      "            \"similarity_score\": 0.8082\n",
      "        }\n",
      "    ],\n",
      "    \"common_treatment_pattern\": [\n",
      "        \"supplemental oxygen\",\n",
      "        \"oxygen therapy\",\n",
      "        \"icu admission\"\n",
      "    ],\n",
      "    \"outcome_pattern\": \"discharged\",\n",
      "    \"confidence_reason\": \"Based on 4 highly similar historical cases, the confidence score obtained is 0.8342.\"\n",
      "}\n",
      "\n",
      "===== Patient Index 1 =====\n",
      "\n",
      "{\n",
      "    \"query_patient_id\": 1,\n",
      "    \"similar_cases\": [\n",
      "        {\n",
      "            \"patient_id\": 6,\n",
      "            \"similarity_score\": 0.8898\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 0,\n",
      "            \"similarity_score\": 0.854\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 2,\n",
      "            \"similarity_score\": 0.8533\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 128,\n",
      "            \"similarity_score\": 0.8479\n",
      "        }\n",
      "    ],\n",
      "    \"common_treatment_pattern\": [\n",
      "        \"oxygen therapy\",\n",
      "        \"icu admission\"\n",
      "    ],\n",
      "    \"outcome_pattern\": \"rehabilitation\",\n",
      "    \"confidence_reason\": \"Based on 4 highly similar historical cases, the confidence score obtained is 0.8613.\"\n",
      "}\n",
      "\n",
      "===== Patient Index 2 =====\n",
      "\n",
      "{\n",
      "    \"query_patient_id\": 2,\n",
      "    \"similar_cases\": [\n",
      "        {\n",
      "            \"patient_id\": 1,\n",
      "            \"similarity_score\": 0.8533\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 6,\n",
      "            \"similarity_score\": 0.8326\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 0,\n",
      "            \"similarity_score\": 0.8082\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 3,\n",
      "            \"similarity_score\": 0.8053\n",
      "        }\n",
      "    ],\n",
      "    \"common_treatment_pattern\": [\n",
      "        \"supplemental oxygen\"\n",
      "    ],\n",
      "    \"outcome_pattern\": \"discharged\",\n",
      "    \"confidence_reason\": \"Based on 4 highly similar historical cases, the confidence score obtained is 0.8248.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# end to end ccms outline\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# mentioning the keywords\n",
    "TREATMENT_KEYWORDS = [\n",
    "    \"oxygen therapy\",\"supplemental oxygen\",\"high flow oxygen\",\n",
    "    \"non invasive ventilation\",\"mechanical ventilation\",\n",
    "    \"remdesivir\",\"dexamethasone\",\"steroid therapy\",\n",
    "    \"antibiotics\",\"heparin\",\"bronchodilator\",\n",
    "    \"physiotherapy\",\"pulmonary rehabilitation\",\n",
    "    \"icu admission\",\"critical care monitoring\"\n",
    "]\n",
    "\n",
    "OUTCOME_KEYWORDS = {\n",
    "    \"discharged\": [\"discharged\",\"home discharge\"],\n",
    "    \"rehabilitation\": [\"rehabilitation\",\"rehab clinic\"],\n",
    "    \"critical_monitoring\": [\"icu\",\"intensive care\",\"critical\"],\n",
    "    \"improved\": [\"improved\",\"stable condition\"]\n",
    "}\n",
    "\n",
    "# similar case function\n",
    "def retrieve_similar_cases(new_embedding, top_n=4):\n",
    "\n",
    "    global stored_embeddings\n",
    "\n",
    "    if new_embedding.ndim == 1:\n",
    "        new_embedding = new_embedding.reshape(1, -1)\n",
    "\n",
    "    similarity_scores = cosine_similarity(\n",
    "        new_embedding,\n",
    "        stored_embeddings\n",
    "    )[0]\n",
    "\n",
    "    # Remove self match\n",
    "    self_index = np.argmax(similarity_scores)\n",
    "    similarity_scores[self_index] = -1\n",
    "\n",
    "    ranked_indices = np.argsort(similarity_scores)[::-1]\n",
    "\n",
    "    top_indices = ranked_indices[:top_n]\n",
    "    top_scores = similarity_scores[top_indices]\n",
    "\n",
    "    return top_indices, top_scores\n",
    "\n",
    "\n",
    "# insight pipeline\n",
    "def endtoend_CCMS(patient_index):\n",
    "\n",
    "    query_embedding = stored_embeddings[patient_index]\n",
    "\n",
    "    # ðŸ”¹ Changed here â†’ top_n=4\n",
    "    top_indices, top_scores = retrieve_similar_cases(\n",
    "        new_embedding=query_embedding,\n",
    "        top_n=4\n",
    "    )\n",
    "\n",
    "    similar_texts = patient_df.iloc[top_indices][\"note_preprocessed\"].tolist()\n",
    "\n",
    "    # Treatment Pattern \n",
    "    treatment_counter = Counter()\n",
    "    for text in similar_texts:\n",
    "        for treatment in TREATMENT_KEYWORDS:\n",
    "            if treatment in text:\n",
    "                treatment_counter.update([treatment])\n",
    "\n",
    "    common_treatments = [t for t, _ in treatment_counter.most_common(3)]\n",
    "\n",
    "    # Outcome Pattern \n",
    "    outcome_counter = Counter()\n",
    "    for text in similar_texts:\n",
    "        for outcome, keywords in OUTCOME_KEYWORDS.items():\n",
    "            if any(k in text for k in keywords):\n",
    "                outcome_counter.update([outcome])\n",
    "\n",
    "    outcome_pattern = \"Not clearly observed\"\n",
    "    if outcome_counter:\n",
    "        outcome_pattern = outcome_counter.most_common(1)[0][0]\n",
    "\n",
    "    # Confidence Score\n",
    "    high_similarity_cases = sum(score > 0.75 for score in top_scores)\n",
    "    confidence_score = round(float(np.mean(top_scores)), 4)\n",
    "\n",
    "    confidence_statement = (\n",
    "        f\"Based on {high_similarity_cases} highly similar historical cases, \"\n",
    "        f\"the confidence score obtained is {confidence_score}.\"\n",
    "    )\n",
    "\n",
    "    # Structured Output \n",
    "    result = {\n",
    "        \"query_patient_id\": patient_df.iloc[patient_index][\"patient_uid\"]\n",
    "        if \"patient_uid\" in patient_df.columns else int(patient_index),\n",
    "\n",
    "        \"similar_cases\": [\n",
    "            {\n",
    "                \"patient_id\": patient_df.iloc[idx][\"patient_uid\"]\n",
    "                if \"patient_uid\" in patient_df.columns else int(idx),\n",
    "                \"similarity_score\": round(float(score), 4)\n",
    "            }\n",
    "            for idx, score in zip(top_indices, top_scores)\n",
    "        ],\n",
    "\n",
    "        \"common_treatment_pattern\": common_treatments,\n",
    "        \"outcome_pattern\": outcome_pattern,\n",
    "        \"confidence_reason\": confidence_statement\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# main execution\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"\\nGenerating insights for First 3 Subjects\\n\")\n",
    "\n",
    "    for patient_index in range(3):\n",
    "\n",
    "        output = endtoend_CCMS(patient_index)\n",
    "\n",
    "        print(f\"\\n===== Patient Index {patient_index} =====\\n\")\n",
    "        print(json.dumps(output, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed89c15c-634e-430a-a077-017c58dc6942",
   "metadata": {},
   "source": [
    "created the end to end ccms pipeline. That provides the provides the confidece reason based on 4 highly similar patient for the common treatment and outcome pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d95c938-f0ae-4dc0-8d9f-607b757d4036",
   "metadata": {},
   "source": [
    "# Testing with input samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde00f89-ab76-4cb4-a97a-27cd5ccbda4d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    " testing the end to end ccms pipeline with the sample input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b108f824-c60c-49a7-b83f-f39908e7d5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter patient symptoms:\n",
      ">>  fever, dry cough, shortness of breath\n",
      "\n",
      "Enter clinical notes:\n",
      ">>  Patient admitted with four day history of fever and persistent dry cough associated with progressive shortness of breath. Oxygen saturation mildly reduced requiring supplemental oxygen therapy. No prior chronic respiratory illness reported.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 527.35it/s, Materializing param=pooler.dense.weight]\n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Output (JSON Format):\n",
      "\n",
      "{\n",
      "    \"similar_cases\": [\n",
      "        {\n",
      "            \"patient_id\": 60,\n",
      "            \"similarity_score\": 0.6396\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 59,\n",
      "            \"similarity_score\": 0.598\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 9,\n",
      "            \"similarity_score\": 0.572\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 192,\n",
      "            \"similarity_score\": 0.5636\n",
      "        }\n",
      "    ],\n",
      "    \"common_treatment_pattern\": [\n",
      "        \"oxygen therapy\",\n",
      "        \"high flow oxygen\",\n",
      "        \"remdesivir\"\n",
      "    ],\n",
      "    \"confidence_score\": \"Based on 4 highly similar historical cases, the confidence score obtained is 0.5933.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# end to end ccms pipeline\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.preprocessing import normalize\n",
    "# defining the keyword\n",
    "TREATMENT_KEYWORDS = [\n",
    "    \"oxygen therapy\",\"supplemental oxygen\",\"high flow oxygen\",\n",
    "    \"non invasive ventilation\",\"mechanical ventilation\",\n",
    "    \"remdesivir\",\"dexamethasone\",\"steroid therapy\",\n",
    "    \"antibiotics\",\"heparin\",\"bronchodilator\",\n",
    "    \"physiotherapy\",\"pulmonary rehabilitation\",\n",
    "    \"icu admission\",\"critical care monitoring\"\n",
    "]\n",
    "#preprocessing of data\n",
    "IMPORTANT_WORDS = {\"no\",\"not\",\"without\",\"with\",\"before\",\"after\",\"during\",\"since\"}\n",
    "CUSTOM_STOPWORDS = ENGLISH_STOP_WORDS.difference(IMPORTANT_WORDS)\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in CUSTOM_STOPWORDS]\n",
    "\n",
    "    return \" \".join(words)\n",
    "# loading of embedding model\n",
    "def load_embedding_model():\n",
    "    return SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "# finding the similar patient cases\n",
    "def retrieve_similar_cases(new_embedding, top_n=4):\n",
    "\n",
    "    global stored_embeddings\n",
    "\n",
    "    if new_embedding.ndim == 1:\n",
    "        new_embedding = new_embedding.reshape(1, -1)\n",
    "\n",
    "    new_embedding = normalize(new_embedding, norm=\"l2\")\n",
    "\n",
    "    similarity_scores = cosine_similarity(\n",
    "        new_embedding,\n",
    "        stored_embeddings\n",
    "    )[0]\n",
    "\n",
    "    ranked_indices = np.argsort(similarity_scores)[::-1]\n",
    "\n",
    "    top_indices = ranked_indices[:top_n]\n",
    "    top_scores = similarity_scores[top_indices]\n",
    "\n",
    "    return top_indices, top_scores\n",
    "# end to end ccms pipelin\n",
    "def run_user_CCMS(symptoms, notes):\n",
    "\n",
    "    global patient_df\n",
    "\n",
    "    #  Combine & Preprocess \n",
    "    combined_text = preprocess_text(symptoms + \" \" + notes)\n",
    "\n",
    "    #  Generate Embedding \n",
    "    model = load_embedding_model()\n",
    "\n",
    "    query_embedding = model.encode(\n",
    "        [combined_text],\n",
    "        convert_to_numpy=True\n",
    "    )[0]\n",
    "\n",
    "    # Retrieve Similar Cases \n",
    "    top_indices, top_scores = retrieve_similar_cases(\n",
    "        new_embedding=query_embedding,\n",
    "        top_n=4\n",
    "    )\n",
    "\n",
    "    similar_texts = patient_df.iloc[top_indices][\"note_preprocessed\"].tolist()\n",
    "\n",
    "    # Treatment Pattern Extraction \n",
    "    treatment_counter = Counter()\n",
    "    for text in similar_texts:\n",
    "        for treatment in TREATMENT_KEYWORDS:\n",
    "            if treatment in text:\n",
    "                treatment_counter.update([treatment])\n",
    "\n",
    "    common_treatments = [t for t, _ in treatment_counter.most_common(3)]\n",
    "\n",
    "    # Confidence Score \n",
    "    confidence_score = round(float(np.mean(top_scores)), 4)\n",
    "    high_similarity_cases = sum(score > 0.5 for score in top_scores)\n",
    "    confidence_statement = (\n",
    "        f\"Based on {high_similarity_cases} highly similar historical cases, \"\n",
    "        f\"the confidence score obtained is {confidence_score}.\" )\n",
    "\n",
    "    #  Structured Output \n",
    "    result = {\n",
    "        \"similar_cases\": [\n",
    "            {\n",
    "                \"patient_id\": patient_df.iloc[idx][\"patient_uid\"]\n",
    "                if \"patient_uid\" in patient_df.columns else int(idx),\n",
    "                \"similarity_score\": round(float(score), 4)\n",
    "            }\n",
    "            for idx, score in zip(top_indices, top_scores)\n",
    "        ],\n",
    "        \"common_treatment_pattern\": common_treatments,\n",
    "        \"confidence_score\": confidence_statement\n",
    "    }\n",
    "\n",
    "    return result\n",
    "# main execution\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    symptoms_input = input(\"Enter patient symptoms:\\n>> \")\n",
    "    notes_input = input(\"\\nEnter clinical notes:\\n>> \")\n",
    "\n",
    "    output = run_user_CCMS(symptoms_input, notes_input)\n",
    "\n",
    "    print(\"\\nFinal Output (JSON Format):\\n\")\n",
    "    print(json.dumps(output, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e00bd31-474e-4d8d-b0e2-24b3996c547c",
   "metadata": {},
   "source": [
    "Tested the developed end to end ccms pipeline with the sample input 1. From the input provided it finds the confidence score of 0.59 from the top 4 similar cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6f9b6a-ebdf-41ea-bc73-d7fe520a44d7",
   "metadata": {},
   "source": [
    "Testing the end to end ccms pipeline with the input sample 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fd5c174-cf50-41ab-95ff-5929e0798f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter patient symptoms:\n",
      ">>  oxygen desaturation, dyspnea, fatigue\n",
      "\n",
      "Enter clinical notes:\n",
      ">>  Elderly male presented with worsening dyspnea and oxygen desaturation over the past two days. Patient required high flow oxygen support and close monitoring in intensive care unit. Fatigue and respiratory distress observed during minimal exertion.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 332.02it/s, Materializing param=pooler.dense.weight]\n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Output (JSON Format):\n",
      "\n",
      "{\n",
      "    \"similar_cases\": [\n",
      "        {\n",
      "            \"patient_id\": 9,\n",
      "            \"similarity_score\": 0.6081\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 8,\n",
      "            \"similarity_score\": 0.5709\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 6,\n",
      "            \"similarity_score\": 0.5533\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 2,\n",
      "            \"similarity_score\": 0.5462\n",
      "        }\n",
      "    ],\n",
      "    \"common_treatment_pattern\": [\n",
      "        \"oxygen therapy\",\n",
      "        \"icu admission\"\n",
      "    ],\n",
      "    \"confidence_score\": \"Based on 4 highly similar historical cases, the confidence score obtained is 0.5696.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# end to end ccms pipeline\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.preprocessing import normalize\n",
    "# defining the keyword\n",
    "TREATMENT_KEYWORDS = [\n",
    "    \"oxygen therapy\",\"supplemental oxygen\",\"high flow oxygen\",\n",
    "    \"non invasive ventilation\",\"mechanical ventilation\",\n",
    "    \"remdesivir\",\"dexamethasone\",\"steroid therapy\",\n",
    "    \"antibiotics\",\"heparin\",\"bronchodilator\",\n",
    "    \"physiotherapy\",\"pulmonary rehabilitation\",\n",
    "    \"icu admission\",\"critical care monitoring\"\n",
    "]\n",
    "#preprocessing of data\n",
    "IMPORTANT_WORDS = {\"no\",\"not\",\"without\",\"with\",\"before\",\"after\",\"during\",\"since\"}\n",
    "CUSTOM_STOPWORDS = ENGLISH_STOP_WORDS.difference(IMPORTANT_WORDS)\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in CUSTOM_STOPWORDS]\n",
    "\n",
    "    return \" \".join(words)\n",
    "# loading of embedding model\n",
    "def load_embedding_model():\n",
    "    return SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "# finding the similar patient cases\n",
    "def retrieve_similar_cases(new_embedding, top_n=4):\n",
    "\n",
    "    global stored_embeddings\n",
    "\n",
    "    if new_embedding.ndim == 1:\n",
    "        new_embedding = new_embedding.reshape(1, -1)\n",
    "\n",
    "    new_embedding = normalize(new_embedding, norm=\"l2\")\n",
    "\n",
    "    similarity_scores = cosine_similarity(\n",
    "        new_embedding,\n",
    "        stored_embeddings\n",
    "    )[0]\n",
    "\n",
    "    ranked_indices = np.argsort(similarity_scores)[::-1]\n",
    "\n",
    "    top_indices = ranked_indices[:top_n]\n",
    "    top_scores = similarity_scores[top_indices]\n",
    "\n",
    "    return top_indices, top_scores\n",
    "# end to end ccms pipelin\n",
    "def run_user_CCMS(symptoms, notes):\n",
    "\n",
    "    global patient_df\n",
    "\n",
    "    #  Combine & Preprocess \n",
    "    combined_text = preprocess_text(symptoms + \" \" + notes)\n",
    "\n",
    "    #  Generate Embedding \n",
    "    model = load_embedding_model()\n",
    "\n",
    "    query_embedding = model.encode(\n",
    "        [combined_text],\n",
    "        convert_to_numpy=True\n",
    "    )[0]\n",
    "\n",
    "    # Retrieve Similar Cases \n",
    "    top_indices, top_scores = retrieve_similar_cases(\n",
    "        new_embedding=query_embedding,\n",
    "        top_n=4\n",
    "    )\n",
    "\n",
    "    similar_texts = patient_df.iloc[top_indices][\"note_preprocessed\"].tolist()\n",
    "\n",
    "    # Treatment Pattern Extraction \n",
    "    treatment_counter = Counter()\n",
    "    for text in similar_texts:\n",
    "        for treatment in TREATMENT_KEYWORDS:\n",
    "            if treatment in text:\n",
    "                treatment_counter.update([treatment])\n",
    "\n",
    "    common_treatments = [t for t, _ in treatment_counter.most_common(3)]\n",
    "\n",
    "    # Confidence Score \n",
    "    confidence_score = round(float(np.mean(top_scores)), 4)\n",
    "    high_similarity_cases = sum(score > 0.5 for score in top_scores)\n",
    "    confidence_statement = (\n",
    "        f\"Based on {high_similarity_cases} highly similar historical cases, \"\n",
    "        f\"the confidence score obtained is {confidence_score}.\" )\n",
    "\n",
    "    #  Structured Output \n",
    "    result = {\n",
    "        \"similar_cases\": [\n",
    "            {\n",
    "                \"patient_id\": patient_df.iloc[idx][\"patient_uid\"]\n",
    "                if \"patient_uid\" in patient_df.columns else int(idx),\n",
    "                \"similarity_score\": round(float(score), 4)\n",
    "            }\n",
    "            for idx, score in zip(top_indices, top_scores)\n",
    "        ],\n",
    "        \"common_treatment_pattern\": common_treatments,\n",
    "        \"confidence_score\": confidence_statement\n",
    "    }\n",
    "\n",
    "    return result\n",
    "# main execution\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    symptoms_input = input(\"Enter patient symptoms:\\n>> \")\n",
    "    notes_input = input(\"\\nEnter clinical notes:\\n>> \")\n",
    "\n",
    "    output = run_user_CCMS(symptoms_input, notes_input)\n",
    "\n",
    "    print(\"\\nFinal Output (JSON Format):\\n\")\n",
    "    print(json.dumps(output, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33391371-b1ed-4481-9ced-61626b0a15d8",
   "metadata": {},
   "source": [
    "Tested the developed end to end ccms pipeline with the sample input two. the output shows that confidence score of 0.57 for the provided user input based on top 4 highly similar cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630cfeda-f978-4d02-a35c-e800f98605f0",
   "metadata": {},
   "source": [
    "Testing the end to end CCMS pipeline with the sample input 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af36cc71-7d5e-4570-b62e-6f24575353b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter patient symptoms:\n",
      ">>  fever, headache, loss of smell\n",
      "\n",
      "Enter clinical notes:\n",
      ">>  Patient reported low grade fever with persistent headache and recent loss of smell. Respiratory status stable without need for mechanical ventilation. Managed conservatively with monitoring and supportive care.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 562.41it/s, Materializing param=pooler.dense.weight]\n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Output (JSON Format):\n",
      "\n",
      "{\n",
      "    \"similar_cases\": [\n",
      "        {\n",
      "            \"patient_id\": 188,\n",
      "            \"similarity_score\": 0.5236\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 7,\n",
      "            \"similarity_score\": 0.5226\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 186,\n",
      "            \"similarity_score\": 0.495\n",
      "        },\n",
      "        {\n",
      "            \"patient_id\": 425,\n",
      "            \"similarity_score\": 0.4843\n",
      "        }\n",
      "    ],\n",
      "    \"common_treatment_pattern\": [\n",
      "        \"mechanical ventilation\",\n",
      "        \"icu admission\"\n",
      "    ],\n",
      "    \"confidence_score\": \"Based on 2 highly similar historical cases, the confidence score obtained is 0.5064.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# end to end ccms pipeline\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.preprocessing import normalize\n",
    "# defining the keyword\n",
    "TREATMENT_KEYWORDS = [\n",
    "    \"oxygen therapy\",\"supplemental oxygen\",\"high flow oxygen\",\n",
    "    \"non invasive ventilation\",\"mechanical ventilation\",\n",
    "    \"remdesivir\",\"dexamethasone\",\"steroid therapy\",\n",
    "    \"antibiotics\",\"heparin\",\"bronchodilator\",\n",
    "    \"physiotherapy\",\"pulmonary rehabilitation\",\n",
    "    \"icu admission\",\"critical care monitoring\"\n",
    "]\n",
    "#preprocessing of data\n",
    "IMPORTANT_WORDS = {\"no\",\"not\",\"without\",\"with\",\"before\",\"after\",\"during\",\"since\"}\n",
    "CUSTOM_STOPWORDS = ENGLISH_STOP_WORDS.difference(IMPORTANT_WORDS)\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in CUSTOM_STOPWORDS]\n",
    "\n",
    "    return \" \".join(words)\n",
    "# loading of embedding model\n",
    "def load_embedding_model():\n",
    "    return SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "# finding the similar patient cases\n",
    "def retrieve_similar_cases(new_embedding, top_n=4):\n",
    "\n",
    "    global stored_embeddings\n",
    "\n",
    "    if new_embedding.ndim == 1:\n",
    "        new_embedding = new_embedding.reshape(1, -1)\n",
    "\n",
    "    new_embedding = normalize(new_embedding, norm=\"l2\")\n",
    "\n",
    "    similarity_scores = cosine_similarity(\n",
    "        new_embedding,\n",
    "        stored_embeddings\n",
    "    )[0]\n",
    "\n",
    "    ranked_indices = np.argsort(similarity_scores)[::-1]\n",
    "\n",
    "    top_indices = ranked_indices[:top_n]\n",
    "    top_scores = similarity_scores[top_indices]\n",
    "\n",
    "    return top_indices, top_scores\n",
    "# end to end ccms pipelin\n",
    "def run_user_CCMS(symptoms, notes):\n",
    "\n",
    "    global patient_df\n",
    "\n",
    "    #  Combine & Preprocess \n",
    "    combined_text = preprocess_text(symptoms + \" \" + notes)\n",
    "\n",
    "    #  Generate Embedding \n",
    "    model = load_embedding_model()\n",
    "\n",
    "    query_embedding = model.encode(\n",
    "        [combined_text],\n",
    "        convert_to_numpy=True\n",
    "    )[0]\n",
    "\n",
    "    # Retrieve Similar Cases \n",
    "    top_indices, top_scores = retrieve_similar_cases(\n",
    "        new_embedding=query_embedding,\n",
    "        top_n=4\n",
    "    )\n",
    "\n",
    "    similar_texts = patient_df.iloc[top_indices][\"note_preprocessed\"].tolist()\n",
    "\n",
    "    # Treatment Pattern Extraction \n",
    "    treatment_counter = Counter()\n",
    "    for text in similar_texts:\n",
    "        for treatment in TREATMENT_KEYWORDS:\n",
    "            if treatment in text:\n",
    "                treatment_counter.update([treatment])\n",
    "\n",
    "    common_treatments = [t for t, _ in treatment_counter.most_common(3)]\n",
    "\n",
    "    # Confidence Score \n",
    "    confidence_score = round(float(np.mean(top_scores)), 4)\n",
    "    high_similarity_cases = sum(score > 0.5 for score in top_scores)\n",
    "    confidence_statement = (\n",
    "        f\"Based on {high_similarity_cases} highly similar historical cases, \"\n",
    "        f\"the confidence score obtained is {confidence_score}.\" )\n",
    "\n",
    "    #  Structured Output \n",
    "    result = {\n",
    "        \"similar_cases\": [\n",
    "            {\n",
    "                \"patient_id\": patient_df.iloc[idx][\"patient_uid\"]\n",
    "                if \"patient_uid\" in patient_df.columns else int(idx),\n",
    "                \"similarity_score\": round(float(score), 4)\n",
    "            }\n",
    "            for idx, score in zip(top_indices, top_scores)\n",
    "        ],\n",
    "        \"common_treatment_pattern\": common_treatments,\n",
    "        \"confidence_score\": confidence_statement\n",
    "    }\n",
    "\n",
    "    return result\n",
    "# main execution\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    symptoms_input = input(\"Enter patient symptoms:\\n>> \")\n",
    "    notes_input = input(\"\\nEnter clinical notes:\\n>> \")\n",
    "\n",
    "    output = run_user_CCMS(symptoms_input, notes_input)\n",
    "\n",
    "    print(\"\\nFinal Output (JSON Format):\\n\")\n",
    "    print(json.dumps(output, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc53f11-5a0b-499c-9632-4007fd7ecb33",
   "metadata": {},
   "source": [
    "Tested the developed end to end ccms pipeline with the sample input three. the output shows that confidence score of 0.50 (very less confidence value) for the provided user input based on top 4 highly similar cases. This very lesser confidence value is due to lesser overlap of the clinical notes and symptoms with the existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9258763c-db82-48f9-b603-09402467c315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
